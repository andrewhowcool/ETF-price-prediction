{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7g_5SyKLVX5a"
   },
   "source": [
    "趨勢科技 : 台灣ETF價格預測競賽\n",
    "---\n",
    "Kenny Hsieh, 2018/4/30\n",
    "\n",
    "- [官方競賽網站](https://tbrain.trendmicro.com.tw/Competitions/Details/2)\n",
    "- `ETF_Modeling.ipynb` : 資料讀取、資料處理、模型建立、輸出預測結果()\n",
    "- `ETF_Price_Performance.ipynb` : 衡量預測結果，計算分數\n",
    "\n",
    "## Brief Introduction\n",
    "- 依據主辦單位提供之台灣十八檔上市櫃成分證券ETF (截至4/27) 預測下週星期一 (4/30) 之漲跌及價格\n",
    "- 由於礙於背景關係，較缺乏股票財金等相關領域知識，此次預測策略採用 Long Short-Term Memory (LSTM)時間序列相關神經網路模型來實作\n",
    "- 同時，由於訓練 LSTM 網路需耗費相當大量運算資源，因此使用 Google Colaboratory 提供之雲端 GPU 環境執行訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32183,
     "status": "ok",
     "timestamp": 1525250824613,
     "user": {
      "displayName": "Kenny Hsieh",
      "photoUrl": "//lh6.googleusercontent.com/-cWWSIkjl7Eo/AAAAAAAAAAI/AAAAAAAA86s/jURqY4aeDO0/s50-c-k-no/photo.jpg",
      "userId": "106741566483718677044"
     },
     "user_tz": -480
    },
    "id": "EZXUHSjnA8cY",
    "outputId": "cfea5d9b-20b6-4db2-d7e0-a39e327dcee4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-6ea9f7e0-2614-4b18-ac65-8d41b3422cdb\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-6ea9f7e0-2614-4b18-ac65-8d41b3422cdb\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tetfp.csv to tetfp (2).csv\n"
     ]
    }
   ],
   "source": [
    "# 將股價資料上傳至 Google 雲端\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJtGAr7BVadQ"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1525253501670,
     "user": {
      "displayName": "Kenny Hsieh",
      "photoUrl": "//lh6.googleusercontent.com/-cWWSIkjl7Eo/AAAAAAAAAAI/AAAAAAAA86s/jURqY4aeDO0/s50-c-k-no/photo.jpg",
      "userId": "106741566483718677044"
     },
     "user_tz": -480
    },
    "id": "ZONIOVDGBBow",
    "outputId": "32e77dd4-9ca5-471a-efb3-75d91f6e8331"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"代碼</th>\n",
       "      <th>日期</th>\n",
       "      <th>中文簡稱</th>\n",
       "      <th>開盤價(元)</th>\n",
       "      <th>最高價(元)</th>\n",
       "      <th>最低價(元)</th>\n",
       "      <th>收盤價(元)</th>\n",
       "      <th>成交張數(張)\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"0050</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.40</td>\n",
       "      <td>16,487\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"0050</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.05</td>\n",
       "      <td>54.65</td>\n",
       "      <td>54.85</td>\n",
       "      <td>29,020\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"0050</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.40</td>\n",
       "      <td>54.50</td>\n",
       "      <td>9,837\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"0050</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.55</td>\n",
       "      <td>54.55</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.25</td>\n",
       "      <td>8,910\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"0050</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.20</td>\n",
       "      <td>53.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>12,507\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        \"代碼         日期              中文簡稱  開盤價(元)  最高價(元)  最低價(元)  收盤價(元)  \\\n",
       "0  \"0050    2013-01-02  元大台灣50             54.00   54.65   53.90   54.40   \n",
       "1  \"0050    2013-01-03  元大台灣50             54.90   55.05   54.65   54.85   \n",
       "2  \"0050    2013-01-04  元大台灣50             54.85   54.85   54.40   54.50   \n",
       "3  \"0050    2013-01-07  元大台灣50             54.55   54.55   53.90   54.25   \n",
       "4  \"0050    2013-01-08  元大台灣50             54.00   54.20   53.65   53.90   \n",
       "\n",
       "       成交張數(張)\"  \n",
       "0       16,487\"  \n",
       "1       29,020\"  \n",
       "2        9,837\"  \n",
       "3        8,910\"  \n",
       "4       12,507\"  "
      ]
     },
     "execution_count": 338,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 將日期欄位轉變為 datetime 格式\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y%m%d')\n",
    "\n",
    "etf_price = pd.read_csv('tetfp.csv', encoding = 'Big5', sep = '\",\"', header = 0, parse_dates=['日期'], date_parser = dateparse)\n",
    "etf_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1525253504101,
     "user": {
      "displayName": "Kenny Hsieh",
      "photoUrl": "//lh6.googleusercontent.com/-cWWSIkjl7Eo/AAAAAAAAAAI/AAAAAAAA86s/jURqY4aeDO0/s50-c-k-no/photo.jpg",
      "userId": "106741566483718677044"
     },
     "user_tz": -480
    },
    "id": "5mdStzjJBD-f",
    "outputId": "8e5f32c0-a377-48d0-c3e8-7442495d3a2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0050</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.40</td>\n",
       "      <td>16,487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0050</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.05</td>\n",
       "      <td>54.65</td>\n",
       "      <td>54.85</td>\n",
       "      <td>29,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0050</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.40</td>\n",
       "      <td>54.50</td>\n",
       "      <td>9,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0050</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.55</td>\n",
       "      <td>54.55</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.25</td>\n",
       "      <td>8,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0050</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.20</td>\n",
       "      <td>53.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>12,507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code       Date              Name   Open   High    Low  Close       Volume\n",
       "0  0050 2013-01-02  元大台灣50            54.00  54.65  53.90  54.40       16,487\n",
       "1  0050 2013-01-03  元大台灣50            54.90  55.05  54.65  54.85       29,020\n",
       "2  0050 2013-01-04  元大台灣50            54.85  54.85  54.40  54.50        9,837\n",
       "3  0050 2013-01-07  元大台灣50            54.55  54.55  53.90  54.25        8,910\n",
       "4  0050 2013-01-08  元大台灣50            54.00  54.20  53.65  53.90       12,507"
      ]
     },
     "execution_count": 339,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 清除讀取資料欄位產生的雜項雕點符號、空格\n",
    "etf_price.columns = ['Code', 'Date', 'Name', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "etf_price['Code'] = etf_price['Code'].map(lambda x: x.lstrip('\"').replace(\" \", \"\"))\n",
    "etf_price['Volume'] = etf_price['Volume'].map(lambda x: x.rstrip('\"').rstrip('\",'))\n",
    "#etf_price = etf_price.drop(['Name'], axis = 1)\n",
    "etf_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9LfEkkrVyX0"
   },
   "source": [
    "## Auxiliary Function\n",
    "此次目標為預測18檔ETF股票，每檔股票皆須有特定對應之模型，因此設計函式的型式，以利程式重複利用\n",
    "- 衡量最後一天預測股價表現 : `evaluate_lastday_result()`\n",
    "- 預測隔天預測漲跌、股價：`predict_nextday_result()`\n",
    "- LSTM模型架構設計：`Pipeline_LSTM()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l_4xs3_KwZV-"
   },
   "outputs": [],
   "source": [
    "def evaluate_lastday_result(code, date, today, predict):\n",
    "  \n",
    "  lastday_date = date + timedelta(days = 1)\n",
    "\n",
    "  result = pd.DataFrame(columns = [\"Code\", \"Date\", \"Actual\", \"Evaluate\"])\n",
    "  result.loc[0] = [code, lastday_date.date(), today, predict]\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nbGe1p4sGCdU"
   },
   "outputs": [],
   "source": [
    "def predict_nextday_result(code, date, today, nextday):\n",
    "  \n",
    "  nextday_date = date + timedelta(days = 3)\n",
    "  trend = 1 if nextday > today else -1 if nextday < today else 0\n",
    "  \n",
    "  result = pd.DataFrame(columns = [\"Code\", \"Date\", \"Trend\", \"Predict\"])\n",
    "  result.loc[0] = [code, nextday_date.date(), trend, nextday]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bOT4DIR3_vJN"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Dropout\n",
    "\n",
    "def Pipeline_LSTM(code, dataset):\n",
    "\n",
    "  # 目前設定 Time Window 為 5，後續可調整觀察模型表現\n",
    "  sliding_windows = 5\n",
    "  dataset = dataset.loc[dataset['Code'] == code]\n",
    "  \n",
    "  # 資料正規化，使用 MinMaxScaler 正規化至 0 與 1 之間\n",
    "  sc = MinMaxScaler(feature_range = (0, 1))\n",
    "  train_sc = sc.fit_transform(np.array(dataset['Close'].values).reshape(-1, 1))\n",
    "  \n",
    "  # 切割訓練與測試資料集\n",
    "  X_train = []\n",
    "  y_train = []\n",
    "\n",
    "  for i in range(sliding_windows, train_sc.shape[0]):\n",
    "    X_train.append(train_sc[i - sliding_windows:i, 0])\n",
    "    y_train.append(train_sc[i, 0])\n",
    "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "  \n",
    "  # 建立 LSTM 模型 ： 設計三層LSTM層，並加入 Dropout 減少 Overfitting\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(units = 128,\n",
    "                      input_shape = (X_train.shape[1], 1),\n",
    "                      return_sequences = True))\n",
    "  model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(LSTM(units = 128,\n",
    "                      return_sequences = True))\n",
    "  model.add(Dropout(0.3))\n",
    "  \n",
    "  model.add(LSTM(units = 64))\n",
    "  model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(Dense(units = 1))\n",
    "\n",
    "  print(\"Handling %s ETF\" %code)\n",
    "  \n",
    "  # 設定優化器及損失函數\n",
    "  model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "  model.fit(X_train, y_train, epochs = 70, batch_size = 32, validation_split = 0.1)\n",
    "  \n",
    "  actual_lastday = dataset[\"Close\"][-1:].values[0]\n",
    "  \n",
    "  \n",
    "  # 衡量最後一天預測股價表現\n",
    "  lastday_date = dataset['Date'].iloc[-2]\n",
    "  X_validate = sc.transform(np.reshape(dataset['Close'][-6:-1].values, (-1, 1)))\n",
    "  X_validate = np.reshape(X_validate, (X_validate.shape[1], X_validate.shape[0], 1))\n",
    "  \n",
    "  predict_lastday = model.predict(X_validate)\n",
    "  predict_lastday = float(sc.inverse_transform(predict_lastday)[0])\n",
    "  evaluate_lastday_df = evaluate_lastday_result(code, lastday_date, actual_lastday, predict_lastday)\n",
    "  \n",
    "  # 預測隔天預測漲跌、股價\n",
    "  nextday_date = dataset['Date'].iloc[-1]\n",
    "  X_test = sc.transform(np.reshape(dataset['Close'][-5:].values, (-1, 1)))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[1], X_test.shape[0], 1))\n",
    "  \n",
    "  predict_nextday = model.predict(X_test)\n",
    "  predict_nextday = float(sc.inverse_transform(predict_nextday)[0])\n",
    "  predict_nextday_df = predict_nextday_result(code, nextday_date, actual_lastday, predict_nextday)\n",
    "  \n",
    "  return evaluate_lastday_df, predict_nextday_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-cmUWdpX0dN"
   },
   "source": [
    "## Predicting Eighteen ETF Stock Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 44081
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3022456,
     "status": "ok",
     "timestamp": 1525256605418,
     "user": {
      "displayName": "Kenny Hsieh",
      "photoUrl": "//lh6.googleusercontent.com/-cWWSIkjl7Eo/AAAAAAAAAAI/AAAAAAAA86s/jURqY4aeDO0/s50-c-k-no/photo.jpg",
      "userId": "106741566483718677044"
     },
     "user_tz": -480
    },
    "id": "mommOlA6A5j5",
    "outputId": "ff4abf5b-6735-43a9-f787-99c693c47ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling 0050 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 32s 27ms/step - loss: 0.0340 - val_loss: 0.0125\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 7/70\n",
      " 352/1168 [========>.....................] - ETA: 1s - loss: 0.00231168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 14/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00291168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 0.00341168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 41/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00161168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 48/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00141168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 9.9416e-04\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.4673e-04\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 9.5821e-04\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 8.9891e-04\n",
      "Epoch 61/70\n",
      " 928/1168 [======================>.......] - ETA: 0s - loss: 0.00111168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.5188e-04\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 9.5939e-04\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 8.1731e-04\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 8.3025e-04\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 8.7726e-04\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0051 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 31s 27ms/step - loss: 0.0660 - val_loss: 0.0065\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 4/70\n",
      " 544/1168 [============>.................] - ETA: 1s - loss: 0.00571168/1168 [==============================] - 2s 2ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 11/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00361168/1168 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 31/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00401168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 38/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00271168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 45/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00281168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 58/70\n",
      "1056/1168 [==========================>...] - ETA: 0s - loss: 0.00231168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 65/70\n",
      "  64/1168 [>.............................] - ETA: 2s - loss: 0.00191168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0052 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 31s 26ms/step - loss: 0.0238 - val_loss: 0.0051\n",
      "Epoch 2/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00211168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 9/70\n",
      " 224/1168 [====>.........................] - ETA: 1s - loss: 0.00211168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 22/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00161168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 29/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00131168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 42/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00111168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 49/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.0011    1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.9997e-04 - val_loss: 0.0014\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.9607e-04 - val_loss: 0.0019\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 55/70\n",
      "1120/1168 [===========================>..] - ETA: 0s - loss: 9.4014e-041168/1168 [==============================] - 2s 2ms/step - loss: 9.4376e-04 - val_loss: 0.0027\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 8.5719e-04 - val_loss: 0.0035\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0034\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.9398e-04 - val_loss: 0.0014\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.7200e-04 - val_loss: 0.0013\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.0869e-04 - val_loss: 0.0014\n",
      "Epoch 61/70\n",
      "1152/1168 [============================>.] - ETA: 0s - loss: 9.9819e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 8.8900e-04 - val_loss: 0.0013\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.1318e-04 - val_loss: 0.0031\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.2648e-04 - val_loss: 0.0019\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 8.1008e-04 - val_loss: 0.0013\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 8.7467e-04 - val_loss: 0.0015\n",
      "Epoch 67/70\n",
      " 512/1168 [============>.................] - ETA: 1s - loss: 8.7684e-041168/1168 [==============================] - 2s 2ms/step - loss: 8.5708e-04 - val_loss: 0.0014\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.7849e-04 - val_loss: 0.0037\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 8.4970e-04 - val_loss: 0.0016\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 8.4654e-04 - val_loss: 0.0039\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0053 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 32s 27ms/step - loss: 0.0386 - val_loss: 0.0019\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 3/70\n",
      " 704/1168 [=================>............] - ETA: 0s - loss: 0.00291168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 10/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00351168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 23/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00201168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 30/70\n",
      "  64/1168 [>.............................] - ETA: 2s - loss: 0.00191168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 43/70\n",
      "1120/1168 [===========================>..] - ETA: 0s - loss: 0.00151168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 50/70\n",
      " 192/1168 [===>..........................] - ETA: 1s - loss: 0.00121168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 57/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 9.3444e-041168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 64/70\n",
      " 192/1168 [===>..........................] - ETA: 1s - loss: 9.5373e-041168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0054 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      " 160/1168 [===>..........................] - ETA: 2:52 - loss: 0.20251168/1168 [==============================] - 32s 27ms/step - loss: 0.0534 - val_loss: 0.0054\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 8/70\n",
      " 224/1168 [====>.........................] - ETA: 1s - loss: 0.00441168/1168 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 15/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00361168/1168 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 36/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00401168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 49/70\n",
      "1056/1168 [==========================>...] - ETA: 0s - loss: 0.00251168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 56/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00201168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 69/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00181168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0055 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 32s 27ms/step - loss: 0.0529 - val_loss: 0.0156\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 5/70\n",
      " 544/1168 [============>.................] - ETA: 1s - loss: 0.00481168/1168 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 12/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00371168/1168 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 26/70\n",
      " 160/1168 [===>..........................] - ETA: 1s - loss: 0.00271168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 33/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 0.00371168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 9.9581e-04\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 47/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00181168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 9.1205e-04\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 54/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00221168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 8.4953e-04\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 9.5624e-04\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 9.2259e-04\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 8.8322e-04\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 7.3275e-04\n",
      "Epoch 67/70\n",
      "1152/1168 [============================>.] - ETA: 0s - loss: 0.0016\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 7.3532e-04\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 9.1147e-04\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0056 ETF\n",
      "Train on 1169 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1169/1169 [==============================] - 33s 28ms/step - loss: 0.0692 - val_loss: 0.0116\n",
      "Epoch 2/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 3/70\n",
      " 224/1169 [====>.........................] - ETA: 1s - loss: 0.00841169/1169 [==============================] - 2s 2ms/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 4/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 5/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 6/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 7/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 8/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 9/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 10/70\n",
      "  96/1169 [=>............................] - ETA: 1s - loss: 0.00511169/1169 [==============================] - 2s 2ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 11/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 12/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 13/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 14/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 15/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 16/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 17/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 18/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 19/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 20/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 21/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 22/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 23/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 24/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 25/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 26/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 27/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 28/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 29/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 30/70\n",
      "1024/1169 [=========================>....] - ETA: 0s - loss: 0.00401169/1169 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 31/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 32/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 33/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 34/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 35/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 36/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 37/70\n",
      "  64/1169 [>.............................] - ETA: 1s - loss: 0.00451169/1169 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 38/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 39/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 40/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 41/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 42/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 43/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 44/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 45/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 46/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 47/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 48/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 49/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 50/70\n",
      "1056/1169 [==========================>...] - ETA: 0s - loss: 0.00301169/1169 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 51/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 52/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 53/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 54/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 55/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 56/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 57/70\n",
      "  96/1169 [=>............................] - ETA: 1s - loss: 0.00281169/1169 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 58/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 59/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 60/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 61/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 62/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 63/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 64/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 65/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 9.0921e-04\n",
      "Epoch 66/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 67/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 8.5710e-04\n",
      "Epoch 68/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 69/70\n",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 8.8914e-04\n",
      "Epoch 70/70\n",
      "1152/1169 [============================>.] - ETA: 0s - loss: 0.0023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1169/1169 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0057 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 33s 28ms/step - loss: 0.0376 - val_loss: 0.0063\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 5/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00281168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 12/70\n",
      "  64/1168 [>.............................] - ETA: 2s - loss: 0.00221168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 25/70\n",
      "1056/1168 [==========================>...] - ETA: 0s - loss: 0.00211168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 32/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00141168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 45/70\n",
      "1056/1168 [==========================>...] - ETA: 0s - loss: 0.00151168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 52/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00101168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 65/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00121168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.0815e-04\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 8.8156e-04\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.2579e-04\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0058 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      " 960/1168 [=======================>......] - ETA: 6s - loss: 0.05141168/1168 [==============================] - 33s 29ms/step - loss: 0.0438 - val_loss: 0.0029\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0045 - val_loss: 9.8668e-04\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 8/70\n",
      " 160/1168 [===>..........................] - ETA: 1s - loss: 0.00301168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 15/70\n",
      " 192/1168 [===>..........................] - ETA: 1s - loss: 0.00211168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 8.8403e-04\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 8.8234e-04\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 8.7265e-04\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 9.1387e-04\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 9.1663e-04\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 8.4827e-04\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 8.3042e-04\n",
      "Epoch 29/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 0.00291168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 8.9797e-04\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 8.0329e-04\n",
      "Epoch 35/70\n",
      "1152/1168 [============================>.] - ETA: 0s - loss: 0.0021\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 8.2407e-04\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 8.2040e-04\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 8.2782e-04\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 8.9059e-04\n",
      "Epoch 41/70\n",
      " 608/1168 [==============>...............] - ETA: 1s - loss: 0.00171168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 8.2543e-04\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 7.7522e-04\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 9.0012e-04\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 7.6695e-04\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 47/70\n",
      "1152/1168 [============================>.] - ETA: 0s - loss: 0.0020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 8.0285e-04\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 8.1331e-04\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 53/70\n",
      " 736/1168 [=================>............] - ETA: 0s - loss: 0.00151168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 7.9362e-04\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 6.3674e-04\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 7.5401e-04\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 8.3515e-04\n",
      "Epoch 60/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00181168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 6.4871e-04\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 8.1675e-04\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 6.1809e-04\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 7.4329e-04\n",
      "Epoch 66/70\n",
      "1120/1168 [===========================>..] - ETA: 0s - loss: 0.00131168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 5.8144e-04\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 5.5112e-04\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 0059 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 34s 29ms/step - loss: 0.0374 - val_loss: 0.0357\n",
      "Epoch 2/70\n",
      " 960/1168 [=======================>......] - ETA: 0s - loss: 0.00541168/1168 [==============================] - 2s 2ms/step - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 9/70\n",
      " 128/1168 [==>...........................] - ETA: 1s - loss: 0.00251168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 23/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 0.00291168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 9.6990e-04\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 9.8622e-04\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 9.0192e-04\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 9.2812e-04\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 44/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00111168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 8.3156e-04\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 8.4150e-04\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 9.9719e-04\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 9.6327e-04\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 50/70\n",
      "1120/1168 [===========================>..] - ETA: 0s - loss: 0.00151168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 9.2537e-04\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 8.1046e-04\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 57/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 0.00191168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 7.2758e-04\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 9.4589e-04\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 7.0305e-04\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 8.2107e-04\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 63/70\n",
      "1056/1168 [==========================>...] - ETA: 0s - loss: 0.00131168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 7.3161e-04\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 7.8278e-04\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 6.7047e-04\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 70/70\n",
      "  32/1168 [..............................] - ETA: 2s - loss: 0.00111168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 006201 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 34s 29ms/step - loss: 0.0448 - val_loss: 0.0296\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 6/70\n",
      " 288/1168 [======>.......................] - ETA: 1s - loss: 0.00341168/1168 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 13/70\n",
      " 192/1168 [===>..........................] - ETA: 1s - loss: 0.00331168/1168 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 20/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00201168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0074\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 27/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00241168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 34/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00151168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 48/70\n",
      " 160/1168 [===>..........................] - ETA: 1s - loss: 0.00191168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 55/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00171168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 62/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 8.2467e-041168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 69/70\n",
      " 128/1168 [==>...........................] - ETA: 1s - loss: 0.00161168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 006203 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 35s 30ms/step - loss: 0.0315 - val_loss: 0.0118\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 5/70\n",
      " 736/1168 [=================>............] - ETA: 0s - loss: 0.00301168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 12/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00221168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 25/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00221168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 32/70\n",
      "  64/1168 [>.............................] - ETA: 2s - loss: 0.00251168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0071\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 52/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00141168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 59/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00121168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 9.7157e-04\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 006204 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 35s 30ms/step - loss: 0.0441 - val_loss: 0.0106\n",
      "Epoch 2/70\n",
      " 704/1168 [=================>............] - ETA: 0s - loss: 0.00441168/1168 [==============================] - 2s 2ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 5/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 9/70\n",
      "  96/1168 [=>............................] - ETA: 2s - loss: 0.00441168/1168 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 12/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 19/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 22/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00251168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 26/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 29/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00231168/1168 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0091\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 42/70\n",
      "1024/1168 [=========================>....] - ETA: 0s - loss: 0.00211168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 46/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 49/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.00201168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 53/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 60/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 62/70\n",
      "1056/1168 [==========================>...] - ETA: 0s - loss: 0.00161168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 66/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 69/70\n",
      " 160/1168 [===>..........................] - ETA: 1s - loss: 0.00121168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 9.9070e-04\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 006208 ETF\n",
      "Train on 1168 samples, validate on 130 samples\n",
      "Epoch 1/70\n",
      "1168/1168 [==============================] - 35s 30ms/step - loss: 0.0323 - val_loss: 0.0049\n",
      "Epoch 2/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 3/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 4/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 5/70\n",
      " 512/1168 [============>.................] - ETA: 1s - loss: 0.00271168/1168 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 6/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 7/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 8/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 9/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 11/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 12/70\n",
      "  32/1168 [..............................] - ETA: 1s - loss: 0.00171168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 13/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 14/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 15/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 16/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 18/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 19/70\n",
      "  96/1168 [=>............................] - ETA: 1s - loss: 0.00141168/1168 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 20/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 24/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 25/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 26/70\n",
      "  64/1168 [>.............................] - ETA: 1s - loss: 0.0012    1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 27/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 28/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 29/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 30/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 31/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 32/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 33/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 34/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 35/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 36/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 37/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 38/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 39/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 40/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 41/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 42/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 43/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 44/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 45/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 46/70\n",
      "1088/1168 [==========================>...] - ETA: 0s - loss: 0.00121168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 47/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 48/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 50/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 51/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.8343e-04\n",
      "Epoch 52/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 53/70\n",
      " 128/1168 [==>...........................] - ETA: 1s - loss: 0.0013\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 54/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 55/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 56/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.2752e-04\n",
      "Epoch 57/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 58/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 59/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 8.9022e-04\n",
      "Epoch 60/70\n",
      "  64/1168 [>.............................] - ETA: 2s - loss: 0.00131168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.4269e-04\n",
      "Epoch 61/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 62/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 9.2197e-04\n",
      "Epoch 63/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 8.3084e-04\n",
      "Epoch 64/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 65/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 66/70\n",
      "1152/1168 [============================>.] - ETA: 0s - loss: 0.0011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 8.3446e-04\n",
      "Epoch 67/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 68/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 9.8813e-04 - val_loss: 0.0020\n",
      "Epoch 69/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 70/70\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 00690 ETF\n",
      "Train on 234 samples, validate on 26 samples\n",
      "Epoch 1/70\n",
      "234/234 [==============================] - 34s 146ms/step - loss: 0.2615 - val_loss: 0.0848\n",
      "Epoch 2/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0054\n",
      "Epoch 3/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0445\n",
      "Epoch 4/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0098\n",
      "Epoch 5/70\n",
      "160/234 [===================>..........] - ETA: 0s - loss: 0.0239234/234 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0147\n",
      "Epoch 6/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0053\n",
      "Epoch 7/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0048\n",
      "Epoch 8/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0047\n",
      "Epoch 9/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 10/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0049\n",
      "Epoch 11/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 12/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0056\n",
      "Epoch 13/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0079\n",
      "Epoch 14/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0059\n",
      "Epoch 15/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0060\n",
      "Epoch 16/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 17/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 18/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 19/70\n",
      "160/234 [===================>..........] - ETA: 0s - loss: 0.0096234/234 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0048\n",
      "Epoch 20/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 21/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0051\n",
      "Epoch 22/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 23/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0074\n",
      "Epoch 24/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 25/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0049\n",
      "Epoch 26/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 27/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 28/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0048\n",
      "Epoch 29/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0057\n",
      "Epoch 30/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 31/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 32/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0047\n",
      "Epoch 33/70\n",
      "224/234 [===========================>..] - ETA: 0s - loss: 0.0091\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0049\n",
      "Epoch 34/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0048\n",
      "Epoch 35/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0046\n",
      "Epoch 36/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 37/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 38/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0054\n",
      "Epoch 39/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 40/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 41/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 42/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0048\n",
      "Epoch 43/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0061\n",
      "Epoch 44/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0049\n",
      "Epoch 45/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 46/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 47/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 48/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 49/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0060\n",
      "Epoch 50/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 51/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 52/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 53/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 54/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 55/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 56/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 57/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 58/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 59/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 60/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 61/70\n",
      "192/234 [=======================>......] - ETA: 0s - loss: 0.0104234/234 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 62/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 63/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 64/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 65/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0054\n",
      "Epoch 66/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 67/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 68/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 69/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 70/70\n",
      "234/234 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0053\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 00692 ETF\n",
      "Train on 207 samples, validate on 23 samples\n",
      "Epoch 1/70\n",
      "207/207 [==============================] - 34s 166ms/step - loss: 0.3352 - val_loss: 0.1293\n",
      "Epoch 2/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0781\n",
      "Epoch 3/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0261\n",
      "Epoch 4/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0095\n",
      "Epoch 5/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0192\n",
      "Epoch 6/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0094\n",
      "Epoch 7/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0102\n",
      "Epoch 8/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0093\n",
      "Epoch 9/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0089\n",
      "Epoch 10/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0096\n",
      "Epoch 11/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0102\n",
      "Epoch 12/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0084\n",
      "Epoch 13/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 14/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0084\n",
      "Epoch 15/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0113\n",
      "Epoch 16/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0089\n",
      "Epoch 17/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0108\n",
      "Epoch 18/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0092\n",
      "Epoch 19/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0086\n",
      "Epoch 20/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0106\n",
      "Epoch 21/70\n",
      "128/207 [=================>............] - ETA: 0s - loss: 0.0178207/207 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0081\n",
      "Epoch 22/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 23/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0098\n",
      "Epoch 24/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0091\n",
      "Epoch 25/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0095\n",
      "Epoch 26/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0092\n",
      "Epoch 27/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0096\n",
      "Epoch 28/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0098\n",
      "Epoch 29/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0085\n",
      "Epoch 30/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0080\n",
      "Epoch 31/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0130\n",
      "Epoch 32/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0078\n",
      "Epoch 33/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0083\n",
      "Epoch 34/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0100\n",
      "Epoch 35/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0087\n",
      "Epoch 36/70\n",
      "160/207 [======================>.......] - ETA: 0s - loss: 0.0170207/207 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 37/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0090\n",
      "Epoch 38/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0078\n",
      "Epoch 39/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0089\n",
      "Epoch 40/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 41/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0074\n",
      "Epoch 42/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 43/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0086\n",
      "Epoch 44/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 45/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0080\n",
      "Epoch 46/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0081\n",
      "Epoch 47/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0086\n",
      "Epoch 48/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0080\n",
      "Epoch 49/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0071\n",
      "Epoch 50/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0089\n",
      "Epoch 51/70\n",
      "128/207 [=================>............] - ETA: 0s - loss: 0.0159207/207 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 52/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0096\n",
      "Epoch 53/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0067\n",
      "Epoch 54/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0071\n",
      "Epoch 55/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0082\n",
      "Epoch 56/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0080\n",
      "Epoch 57/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0066\n",
      "Epoch 58/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0065\n",
      "Epoch 59/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 60/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 61/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0059\n",
      "Epoch 62/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 63/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0200\n",
      "Epoch 64/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0088\n",
      "Epoch 65/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0061\n",
      "Epoch 66/70\n",
      "128/207 [=================>............] - ETA: 0s - loss: 0.0101207/207 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0060\n",
      "Epoch 67/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 68/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0076\n",
      "Epoch 69/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0067\n",
      "Epoch 70/70\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0064\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 00701 ETF\n",
      "Train on 148 samples, validate on 17 samples\n",
      "Epoch 1/70\n",
      "148/148 [==============================] - 35s 233ms/step - loss: 0.2073 - val_loss: 0.2750\n",
      "Epoch 2/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0170\n",
      "Epoch 3/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0102\n",
      "Epoch 4/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0891\n",
      "Epoch 5/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0688\n",
      "Epoch 6/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0113\n",
      "Epoch 7/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0141\n",
      "Epoch 8/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0163\n",
      "Epoch 9/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0272\n",
      "Epoch 10/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0118\n",
      "Epoch 11/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0138\n",
      "Epoch 12/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0107\n",
      "Epoch 13/70\n",
      " 64/148 [===========>..................] - ETA: 0s - loss: 0.0224148/148 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0127\n",
      "Epoch 14/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0106\n",
      "Epoch 15/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0128\n",
      "Epoch 16/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0108\n",
      "Epoch 17/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0130\n",
      "Epoch 18/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0112\n",
      "Epoch 19/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0108\n",
      "Epoch 20/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0103\n",
      "Epoch 21/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0103\n",
      "Epoch 22/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0104\n",
      "Epoch 23/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 24/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0126\n",
      "Epoch 25/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0102\n",
      "Epoch 26/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0108\n",
      "Epoch 27/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0158\n",
      "Epoch 28/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0100\n",
      "Epoch 29/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0102\n",
      "Epoch 30/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0120\n",
      "Epoch 31/70\n",
      " 64/148 [===========>..................] - ETA: 0s - loss: 0.0159148/148 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0101\n",
      "Epoch 32/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0097\n",
      "Epoch 33/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0098\n",
      "Epoch 34/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0104\n",
      "Epoch 35/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0098\n",
      "Epoch 36/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0097\n",
      "Epoch 37/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0100\n",
      "Epoch 38/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0098\n",
      "Epoch 39/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0096\n",
      "Epoch 40/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0101\n",
      "Epoch 41/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0094\n",
      "Epoch 42/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0094\n",
      "Epoch 43/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0093\n",
      "Epoch 44/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0096\n",
      "Epoch 45/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0092\n",
      "Epoch 46/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0104\n",
      "Epoch 47/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0094\n",
      "Epoch 48/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0089\n",
      "Epoch 49/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0095\n",
      "Epoch 50/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0090\n",
      "Epoch 51/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0089\n",
      "Epoch 52/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 53/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0085\n",
      "Epoch 54/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0087\n",
      "Epoch 55/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0086\n",
      "Epoch 56/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0102\n",
      "Epoch 57/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0091\n",
      "Epoch 58/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0091\n",
      "Epoch 59/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0081\n",
      "Epoch 60/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0080\n",
      "Epoch 61/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0081\n",
      "Epoch 62/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 63/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0080\n",
      "Epoch 64/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0077\n",
      "Epoch 65/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0079\n",
      "Epoch 66/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0092\n",
      "Epoch 67/70\n",
      " 32/148 [=====>........................] - ETA: 0s - loss: 0.0070148/148 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 68/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0079\n",
      "Epoch 69/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 70/70\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0080\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "Handling 00713 ETF\n",
      "Train on 122 samples, validate on 14 samples\n",
      "Epoch 1/70\n",
      "122/122 [==============================] - 35s 287ms/step - loss: 0.2908 - val_loss: 0.2236\n",
      "Epoch 2/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.1570 - val_loss: 0.0535\n",
      "Epoch 3/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.1018\n",
      "Epoch 4/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0373\n",
      "Epoch 5/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0408\n",
      "Epoch 6/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0378\n",
      "Epoch 7/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0339\n",
      "Epoch 8/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0442\n",
      "Epoch 9/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0355\n",
      "Epoch 10/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0335\n",
      "Epoch 11/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0334\n",
      "Epoch 12/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0336\n",
      "Epoch 13/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0368\n",
      "Epoch 14/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0361\n",
      "Epoch 15/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0335\n",
      "Epoch 16/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0337\n",
      "Epoch 17/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0332\n",
      "Epoch 18/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0327\n",
      "Epoch 19/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0331\n",
      "Epoch 20/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0326\n",
      "Epoch 21/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0340\n",
      "Epoch 22/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0329\n",
      "Epoch 23/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0320\n",
      "Epoch 24/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0320\n",
      "Epoch 25/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0342\n",
      "Epoch 26/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0313\n",
      "Epoch 27/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0324\n",
      "Epoch 28/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0360\n",
      "Epoch 29/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0310\n",
      "Epoch 30/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0307\n",
      "Epoch 31/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0337\n",
      "Epoch 32/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0343\n",
      "Epoch 33/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0315\n",
      "Epoch 34/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0305\n",
      "Epoch 35/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0339\n",
      "Epoch 36/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0328\n",
      "Epoch 37/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0295\n",
      "Epoch 38/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0294\n",
      "Epoch 39/70\n",
      " 96/122 [======================>.......] - ETA: 0s - loss: 0.0319122/122 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0330\n",
      "Epoch 40/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0341\n",
      "Epoch 41/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0287\n",
      "Epoch 42/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0297\n",
      "Epoch 43/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0318\n",
      "Epoch 44/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0287\n",
      "Epoch 45/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0285\n",
      "Epoch 46/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0287\n",
      "Epoch 47/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0278\n",
      "Epoch 48/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0287\n",
      "Epoch 49/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0274\n",
      "Epoch 50/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0270\n",
      "Epoch 51/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0275\n",
      "Epoch 52/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0262\n",
      "Epoch 53/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0252\n",
      "Epoch 54/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0260\n",
      "Epoch 55/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0244\n",
      "Epoch 56/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0262\n",
      "Epoch 57/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0237\n",
      "Epoch 58/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0283\n",
      "Epoch 59/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0226\n",
      "Epoch 60/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0262\n",
      "Epoch 61/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0230\n",
      "Epoch 62/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0273\n",
      "Epoch 63/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0212\n",
      "Epoch 64/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0215\n",
      "Epoch 65/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0207\n",
      "Epoch 66/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0206\n",
      "Epoch 67/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0218\n",
      "Epoch 68/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0198\n",
      "Epoch 69/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 70/70\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0192\n",
      "2018-04-27 00:00:00\n",
      "2018-04-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 將資料集中18檔ETF依次投入模型之中，最後回傳統整之衡量及預測表現\n",
    "etf_code = pd.unique(pd.Series(etf_price[\"Code\"]))\n",
    "\n",
    "evaluate_result = pd.DataFrame()\n",
    "predict_result = pd.DataFrame()\n",
    "\n",
    "## 相當耗費時間\n",
    "for etf in etf_code:\n",
    "  evaluate, predict = Pipeline_LSTM(etf, etf_price)\n",
    "  evaluate_result = evaluate_result.append(evaluate, ignore_index = True)\n",
    "  predict_result = predict_result.append(predict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1525264052196,
     "user": {
      "displayName": "Kenny Hsieh",
      "photoUrl": "//lh6.googleusercontent.com/-cWWSIkjl7Eo/AAAAAAAAAAI/AAAAAAAA86s/jURqY4aeDO0/s50-c-k-no/photo.jpg",
      "userId": "106741566483718677044"
     },
     "user_tz": -480
    },
    "id": "3wLrWcA2EDl9",
    "outputId": "2234af1f-2e5b-4a9a-d6e9-f123bbfb45fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Evaluate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0050</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>79.20</td>\n",
       "      <td>79.684006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0051</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>32.11</td>\n",
       "      <td>31.961449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0052</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>53.20</td>\n",
       "      <td>52.513840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0053</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>34.20</td>\n",
       "      <td>34.336716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0054</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.096197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0055</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>17.04</td>\n",
       "      <td>16.863270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0056</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>25.15</td>\n",
       "      <td>25.144646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0057</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>48.74</td>\n",
       "      <td>48.668575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0058</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>45.06</td>\n",
       "      <td>45.990833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0059</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>41.97</td>\n",
       "      <td>40.994087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>006201</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>13.26</td>\n",
       "      <td>13.305820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>006203</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>36.82</td>\n",
       "      <td>37.144890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>006204</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.232498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>006208</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>46.00</td>\n",
       "      <td>46.030933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00690</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>21.54</td>\n",
       "      <td>21.870966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00692</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>20.84</td>\n",
       "      <td>21.063787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00701</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>20.86</td>\n",
       "      <td>20.870260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00713</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>30.12</td>\n",
       "      <td>30.266701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code        Date  Actual   Evaluate\n",
       "0     0050  2018-04-27   79.20  79.684006\n",
       "1     0051  2018-04-27   32.11  31.961449\n",
       "2     0052  2018-04-27   53.20  52.513840\n",
       "3     0053  2018-04-27   34.20  34.336716\n",
       "4     0054  2018-04-27   23.09  23.096197\n",
       "5     0055  2018-04-27   17.04  16.863270\n",
       "6     0056  2018-04-27   25.15  25.144646\n",
       "7     0057  2018-04-27   48.74  48.668575\n",
       "8     0058  2018-04-27   45.06  45.990833\n",
       "9     0059  2018-04-27   41.97  40.994087\n",
       "10  006201  2018-04-27   13.26  13.305820\n",
       "11  006203  2018-04-27   36.82  37.144890\n",
       "12  006204  2018-04-27   52.10  52.232498\n",
       "13  006208  2018-04-27   46.00  46.030933\n",
       "14   00690  2018-04-27   21.54  21.870966\n",
       "15   00692  2018-04-27   20.84  21.063787\n",
       "16   00701  2018-04-27   20.86  20.870260\n",
       "17   00713  2018-04-27   30.12  30.266701"
      ]
     },
     "execution_count": 349,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 衡量最後一天預測股價表現\n",
    "evaluate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1525264063475,
     "user": {
      "displayName": "Kenny Hsieh",
      "photoUrl": "//lh6.googleusercontent.com/-cWWSIkjl7Eo/AAAAAAAAAAI/AAAAAAAA86s/jURqY4aeDO0/s50-c-k-no/photo.jpg",
      "userId": "106741566483718677044"
     },
     "user_tz": -480
    },
    "id": "uGNolcyx1Gk0",
    "outputId": "4bfee156-b264-412d-96ab-3c890e7e5116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0050</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>79.486275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0051</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.813707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0052</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>52.205582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0053</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>34.138184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0054</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>23.049755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0055</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>16.896467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0056</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>25.056149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0057</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.434689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0058</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>45.758862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0059</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>41.104889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>006201</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>13.223225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>006203</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>37.033825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>006204</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>52.034912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>006208</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>45.840836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00690</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>21.790834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00692</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>20.979530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00701</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.853003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00713</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>30.204332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code        Date Trend    Predict\n",
       "0     0050  2018-04-30     1  79.486275\n",
       "1     0051  2018-04-30    -1  31.813707\n",
       "2     0052  2018-04-30    -1  52.205582\n",
       "3     0053  2018-04-30    -1  34.138184\n",
       "4     0054  2018-04-30    -1  23.049755\n",
       "5     0055  2018-04-30    -1  16.896467\n",
       "6     0056  2018-04-30    -1  25.056149\n",
       "7     0057  2018-04-30    -1  48.434689\n",
       "8     0058  2018-04-30     1  45.758862\n",
       "9     0059  2018-04-30    -1  41.104889\n",
       "10  006201  2018-04-30    -1  13.223225\n",
       "11  006203  2018-04-30     1  37.033825\n",
       "12  006204  2018-04-30    -1  52.034912\n",
       "13  006208  2018-04-30    -1  45.840836\n",
       "14   00690  2018-04-30     1  21.790834\n",
       "15   00692  2018-04-30     1  20.979530\n",
       "16   00701  2018-04-30    -1  20.853003\n",
       "17   00713  2018-04-30     1  30.204332"
      ]
     },
     "execution_count": 350,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 預測隔天預測漲跌、股價\n",
    "predict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrNGU8NbYT88"
   },
   "source": [
    "## Save Result to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Nzay6am906XI"
   },
   "outputs": [],
   "source": [
    "evaluate_result.to_csv(\"evaluate_result.csv\", sep=',', index = False, encoding='utf-8')\n",
    "predict_result.to_csv(\"predict_result.csv\", sep=',', index = False, encoding='utf-8')\n",
    "files.download(\"evaluate_result.csv\")\n",
    "files.download(\"predict_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6A4GlNxkYbmp"
   },
   "source": [
    "## Modeling Process Over\n",
    "- 此筆記本僅記錄到從資料處理、建立模型到最終預測結果，後續衡量表現可參考 `ETF_Price_Performance.ipynb`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "ETF_Modeling.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
